---
layout: about
title: About
permalink: /
subtitle: CS Ph.D. Candidate @ Iowa State University

profile:
  align: right
  image: headshot-new.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <!-- <p> align="center">116 A Atanasoff Hall</p>
    <p align="center">2434 Osborn Dr.</p>
    <p align="center">Ames, Iowa</p> -->


announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 9 # leave blank to include all the news in the `_news` folder
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hi! I am Usman! I am a final-year **PhD candidate and F. Wendell Scholar** in [Computer Science at Iowa State University](https://www.cs.iastate.edu/), advised by Dr. [Robyn Lutz](https://robynlutz.com/) in the [Laboratory for Software Safety](https://softwaresafety.cs.iastate.edu/). My research interests lie at the intersection of **Machine Learning, Software Engineering, AI Safety, and ethics**, to address algorithmic harms and enhance responsible AI practices. I currently serve as the Section Lead for *"Harms to Individuals through AI-Generated Fake Content"* for the 2026 International AI Safety Report, a global initiative chaired by Turing Award winner [Yoshua Bengio](https://yoshuabengio.org/). This initiative, led by the [UK AISI](https://www.aisi.gov.uk/), unites over 100 leading experts, governments, and organizations to assess the frontier risks posed by advanced AI systems. 
 
My research has focused on creating robust, practical approaches to operationalize AI and software safety within complex, data-driven systems, including advancing fairness, mitigating harms from machine learning and AI, and improving safety assurance for autonomous systems (e.g., drones) and AI systems. Iâ€™ve published peer-reviewed research in leading venues in software engineering, machine learning, and AI ethics.

My research focuses on three key areas:

- **Operationalizing AI and Software Safety**
Developing practical frameworks and methodologies to apply system safety principles in complex, data-driven AI systems. My work includes advancing safety assurance approaches for autonomous drones and evaluating risks associated with generative AI systems.

- **Algorithmic Fairness and Harm Mitigation**  
  Investigating how harms from machine learning models manifest and how fairness can be systematically measured and improved. I analyze existing fairness metrics and propose improvements to reduce bias and unfairness.

- **Evaluation and Deployment of Safe AI**  
  Designing transparent evaluation techniques that bridge theoretical AI safety concepts with real-world deployment challenges, focusing on creating actionable tools and guidelines for reliable, fair, and safe AI systems.

Previously, I have worked as a Data Scientist in different sectors like agriculture, manufacturing, and power systems, specializing in forecasting, predictive analytics, and model deployment. I am passionate about translating foundational AI research into practical applications. 

[View my CV here](../assets/pdf/Usman Gohar CV.pdf)
